@Article{9831954,
  author={Mantau, Aprinaldi Jasa and Widayat, Irawan Widi and Adhitya, Yudhi and Prakosa, Setya Widyawan and Leu, Jenq-Shiou and Köppen, Mario},
  booktitle={2022 IEEE 17th International Conference on Control & Automation (ICCA)}, 
  title={A GA-Based Learning Strategy Applied to YOLOv5 for Human Object Detection in UAV Surveillance System}, 
  year={2022},
  volume={22},
  number={01},
  pages={9-14},
  keywords={type:Human Detection, Location awareness,Visualization,Surveillance,Transfer learning,Lighting,Object detection,Autonomous aerial vehicles},
  doi={10.1109/ICCA54724.2022.9831954}}
@Article{9172031,
  author={Das, Lyla B. and Lijiya, A and Jagadanand, G and Aadith, A and Gautham, S and Mohan, Vandanan and Reuben, S and George, Geo},
  booktitle={2020 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={Human Target Search and Detection using Autonomous UAV and Deep learning}, 
  year={2020},
  volume={22},
  number={02},
  pages={55-61},
  keywords={type:Human Detection, UAV,Search,Object detection,RCNN,YOLO,SSD},
  doi={10.1109/IAICT50021.2020.9172031}}
@Article{agriculture14101842,
  AUTHOR = {Zhao, Yun and Li, Yang and Xu, Xing},
  TITLE = {Object Detection in High-Resolution UAV Aerial Remote Sensing Images of Blueberry Canopy Fruits},
  JOURNAL = {Agriculture},
  VOLUME = {14},
  YEAR = {2024},
  NUMBER = {10},
  ARTICLE-NUMBER = {1842},
  URL = {https://www.mdpi.com/2077-0472/14/10/1842},
  ISSN = {2077-0472},
  ABSTRACT = {Blueberries, as one of the more economically rewarding fruits in the fruit industry, play a significant role in fruit detection during their growing season, which is crucial for orchard farmers’ later harvesting and yield prediction. Due to the small size and dense growth of blueberry fruits, manual detection is both time-consuming and labor-intensive. We found that there are few studies utilizing drones for blueberry fruit detection. By employing UAV remote sensing technology and deep learning techniques for detection, substantial human, material, and financial resources can be saved. Therefore, this study collected and constructed a UAV remote sensing target detection dataset for blueberry canopy fruits in a real blueberry orchard environment, which can be used for research on remote sensing target detection of blueberries. To improve the detection accuracy of blueberry fruits, we proposed the PAC3 module, which incorporates location information encoding during the feature extraction process, allowing it to focus on the location information of the targets and thereby reducing the chances of missing blueberry fruits. We adopted a fast convolutional structure instead of the traditional convolutional structure, reducing the model’s parameter count and computational complexity. We proposed the PF-YOLO model and conducted experimental comparisons with several excellent models, achieving improvements in mAP of 5.5%, 6.8%, 2.5%, 2.1%, 5.7%, 2.9%, 1.5%, and 3.4% compared to Yolov5s, Yolov5l, Yolov5s-p6, Yolov5l-p6, Tph-Yolov5, Yolov8n, Yolov8s, and Yolov9c, respectively. We also introduced a non-maximal suppression algorithm, Cluster-NMF, which accelerates inference speed through matrix parallel computation and merges multiple high-quality target detection frames to generate an optimal detection frame, enhancing the efficiency of blueberry canopy fruit detection without compromising inference speed.},
  DOI = {10.3390/agriculture14101842},
  keywords={type:Crop Detection,UAV,PF-YOLO}
}
@Article{rs15194696,
  AUTHOR = {Feng, Chao and Zhang, Wenjiang and Deng, Hui and Dong, Lei and Zhang, Houxi and Tang, Ling and Zheng, Yu and Zhao, Zihan},
  TITLE = {A Combination of OBIA and Random Forest Based on Visible UAV Remote Sensing for Accurately Extracted Information about Weeds in Areas with Different Weed Densities in Farmland},
  JOURNAL = {Remote Sensing},
  VOLUME = {15},
  YEAR = {2023},
  NUMBER = {19},
  ARTICLE-NUMBER = {4696},
  URL = {https://www.mdpi.com/2072-4292/15/19/4696},
  ISSN = {2072-4292},
  ABSTRACT = {Weeds have a significant impact on the growth of rice. Accurate information about weed infestations can provide farmers with important information to facilitate the precise use of chemicals. In this study, we utilized visible light images captured by UAVs to extract information about weeds in areas of two densities on farmland. First, the UAV images were segmented using an optimal segmentation scale, and the spectral, texture, index, and geometric features of each segmented object were extracted. Cross-validation and recursive feature elimination techniques were combined to reduce the dimensionality of all features to obtain a better feature set. Finally, we analyzed the extraction effect of different feature dimensions based on the random forest (RF) algorithm to determine the best feature dimensions, and then we further analyzed the classification result of machine learning algorithms, such as random forest, support vector machine (SVM), decision tree (DT), and K-nearest neighbors (KNN) and compared them based on the best feature dimensions. Using the extraction results of the best classifier, we created a zoning map of the weed infestations in the study area. The results indicated that the best feature subset achieved the highest accuracy, with respective overall accuracies of 95.38% and 91.33% for areas with dense and sparse weed densities, respectively, and F1-scores of 94.20% and 90.57. Random forest provided the best extraction results for each machine learning algorithm in the two experimental areas. When compared to the other algorithms, it improved the overall accuracy by 1.74–12.14% and 7.51–11.56% for areas with dense and sparse weed densities, respectively. The F1-score improved by 1.89–17.40% and 7.85–10.80%. Therefore, the combination of object-based image analysis (OBIA) and random forest based on UAV remote sensing accurately extracted information about weeds in areas with different weed densities for farmland, providing effective information support for weed management.},
  DOI = {10.3390/rs15194696},
  keywords={type:Crop Detection,UAV,Random Forest, Weed Detection}
}
@Article{rs15143582,
  AUTHOR = {Khoramshahi, Ehsan and Näsi, Roope and Rua, Stefan and Oliveira, Raquel A. and Päivänsalo, Axel and Niemeläinen, Oiva and Niskanen, Markku and Honkavaara, Eija},
  TITLE = {A Novel Deep Multi-Image Object Detection Approach for Detecting Alien Barleys in Oat Fields Using RGB UAV Images},
  JOURNAL = {Remote Sensing},
  VOLUME = {15},
  YEAR = {2023},
  NUMBER = {14},
  ARTICLE-NUMBER = {3582},
  URL = {https://www.mdpi.com/2072-4292/15/14/3582},
  ISSN = {2072-4292},
  ABSTRACT = {Oat products are significant parts of a healthy diet. Pure oat is gluten-free, which makes it an excellent choice for people with celiac disease. Elimination of alien cereals is important not only in gluten-free oat production but also in seed production. Detecting gluten-rich crops such as wheat, rye, and barley in an oat production field is an important initial processing step in gluten-free food industries; however, this particular step can be extremely time consuming. This article demonstrates the potential of emerging drone techniques for identifying alien barleys in an oat stand. The primary aim of this study was to develop and assess a novel machine-learning approach that automatically detects and localizes barley plants by employing drone images. An Unbiased Teacher v2 semi-supervised object-detection deep convolutional neural network (CNN) was employed to detect barley ears in drone images with a 1.5 mm ground sample distance. The outputs of the object detector were transformed into ground coordinates by employing a photogrammetric technique. The ground coordinates were analyzed with the kernel density estimate (KDE) clustering approach to form a probabilistic map of the ground locations of barley plants. The detector was trained using a dataset from a reference data production site (located in Ilmajoki, Finland) and tested using a 10% independent test data sample from the same site and a completely unseen dataset from a commercial gluten-free oats production field in Seinäjoki, Finland. In the reference data production dataset, 82.9% of the alien barley plants were successfully detected; in the independent farm test dataset, 60.5% of the ground-truth barley plants were correctly recognized. Our results establish the usefulness and importance of the proposed drone-based ultra-high-resolution red–green–blue (RGB) imaging approach for modern grain production industries.},
  DOI = {10.3390/rs15143582},
  keywords={type:Crop Detection,UAV,alien barley detection}
}
@ARTICLE{8807383,
  author={Kellenberger, Benjamin and Marcos, Diego and Lobry, Sylvain and Tuia, Devis},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Half a Percent of Labels is Enough: Efficient Animal Detection in UAV Imagery Using Deep CNNs and Active Learning}, 
  year={2019},
  volume={57},
  number={12},
  pages={9524-9533},
  keywords={type: Animal Detection,Animals,Detectors,Data models,Unmanned aerial vehicles,Adaptation models,Biological system modeling,Predictive models,Active Learning (AL),animal census,convolutional neural networks,domain adaptation,object detection,Optimal Transport (OT),unmanned aerial vehicles},
  doi={10.1109/TGRS.2019.2927393}}
@Article{d14080624,
  AUTHOR = {Ma, Jiarong and Hu, Zhuowei and Shao, Quanqin and Wang, Yongcai and Zhou, Yanqiong and Liu, Jiayan and Liu, Shuchao},
  TITLE = {Detection of Large Herbivores in UAV Images: A New Method for Small Target Recognition in Large-Scale Images},
  JOURNAL = {Diversity},
  VOLUME = {14},
  YEAR = {2022},
  NUMBER = {8},
  ARTICLE-NUMBER = {624},
  URL = {https://www.mdpi.com/1424-2818/14/8/624},
  ISSN = {1424-2818},
  ABSTRACT = {Algorithm design and implementation for the detection of large herbivores from low-altitude (200 m–350 m) UAV remote sensing images faces two key problems: (1) the size of a single image from the UAV is too large, and the mainstream algorithm cannot adapt to it, and (2) the number of animals in the image is very small and densely distributed, which makes the model prone to missed detection. This paper proposes the following solutions: For the problem of animal size, we optimized the Faster-RCNN algorithm in terms of three aspects: selecting a HRNet feature extraction network that is more suitable for small target detection, using K-means clustering to obtain the anchor frame size that matches the experimental object, and using NMS to eliminate detection frames that have sizes inconsistent with the size range of the detection target after the algorithm generates the target detection frames. For image size, bisection segmentation was used when training the model, and when using the model to detect the whole image, we propose the use of a new overlapping segmentation detection method. The experimental results obtained for detecting yaks, Tibetan sheep (Tibetana folia), and the Tibetan wild ass in remote sensing images of low-altitude UAV from Maduo County, the source region of the Yellow River, show that the mean average precision (mAP) and average recall (AR) of the optimized Faster-RCNN algorithm are 97.2% and 98.2%, respectively, which are 9.5% and 12.1% higher than the values obtained by the original Faster-RCNN. In addition, the results obtained from applying the new overlap segmentation method to the whole UAV image detection process also show that the new overlap segmentation method can effectively solve the problems of the detection frames not fitting the target, missing detection, and creating false alarms due to bisection segmentation.},
  DOI = {10.3390/d14080624},
  keywords={type:Animal Detection}
}
@Article{10373473,
  author={Kurniadi, Fauzan Andaru and Setianingsih, Casi and Syaputra, Randy Erfa},
  booktitle={2023 IEEE 9th International Conference on Smart Instrumentation, Measurement and Applications (ICSIMA)}, 
  title={Innovation in Livestock Surveillance: Applying the YOLO Algorithm to UAV Imagery and Videography}, 
  year={2023},
  volume={},
  number={},
  pages={246-251},
  keywords={type:Animal Detection,Meters,YOLO,Training,Technological innovation,Cows,Autonomous aerial vehicles,Agriculture,YOLO,YOLOv5,Object detection,Training,Hyperparameter,Drone,Dataset},
  doi={10.1109/ICSIMA59853.2023.10373473}}
@Article{app122312236,
  AUTHOR = {Liu, Huanhua and Yu, Yonghao and Liu, Shengzong and Wang, Wei},
  TITLE = {A Military Object Detection Model of UAV Reconnaissance Image and Feature Visualization},
  JOURNAL = {Applied Sciences},
  VOLUME = {12},
  YEAR = {2022},
  NUMBER = {23},
  ARTICLE-NUMBER = {12236},
  URL = {https://www.mdpi.com/2076-3417/12/23/12236},
  ISSN = {2076-3417},
  ABSTRACT = {Military object detection from Unmanned Aerial Vehicle (UAV) reconnaissance images faces challenges, including lack of image data, images with poor quality, and small objects. In this work, we simulate UAV low-altitude reconnaissance and construct the UAV reconnaissance image tank database UAVT-3. Then, we improve YOLOv5 and propose UAVT-YOLOv5 for object detection of UAV images. First, data augmentation of blurred images is introduced to improve the accuracy of fog and motion-blurred images. Secondly, a large-scale feature map together with multi-scale feedback is added to improve the recognition ability of small objects. Thirdly, we optimize the loss function by increasing the loss penalty of small objects and classes with fewer samples. Finally, the anchor boxes are optimized by clustering the ground truth object box of UAVT-3. The feature visualization technique Class Action Mapping (CAM) is introduced to explore the mechanisms of the proposed model. The experimental results of the improved model evaluated on UAVT-3 show that the mAP reaches 99.2%, an increase of 2.1% compared with YOLOv5, the detection speed is 40 frames per second, and data augmentation of blurred images yields an mAP increase of 20.4% and 26.6% for fog and motion blur images detection. The class action maps show the discriminant region of the tanks is the turret for UAVT-YOLOv5.},
  DOI = {10.3390/app122312236},
  keywords={type:Military Object Detection}
}
@Article{8127090,
  author={Kellenberger, Benjamin and Volpi, Michele and Tuia, Devis},
  booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, 
  title={Fast animal detection in UAV images using convolutional neural networks}, 
  year={2017},
  volume={},
  number={},
  pages={866-869},
  keywords={type:Animal Dectection,Proposals,Predictive models,Wildlife,Feature extraction,Remote sensing},
  doi={10.1109/IGARSS.2017.8127090}}